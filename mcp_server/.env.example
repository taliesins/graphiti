# Graphiti MCP Server Environment Configuration

# --- Graph Database Provider Configuration ---
GRAPH_DB_PROVIDER=neo4j # Options: "neo4j", "kuzudb"

# --- Neo4j Configuration (only if GRAPH_DB_PROVIDER="neo4j") ---
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=demodemo

# --- KuzuDB Configuration (only if GRAPH_DB_PROVIDER="kuzudb") ---
# KUZUDB_DATABASE_PATH=./data/graphiti_kuzudb # Example path, ensure directory exists.
# KUZUDB_IN_MEMORY=False # Set to True for in-memory mode (DATABASE_PATH might be ignored or used differently by Kuzu)


# --- OpenAI API Configuration ---
# Required for LLM and Embedding operations if not using Azure
OPENAI_API_KEY=your_openai_api_key_here
MODEL_NAME=gpt-4.1-mini
SMALL_MODEL_NAME=gpt-4.1-nano # Optional, for less complex LLM tasks
EMBEDDER_MODEL_NAME=text-embedding-3-small
LLM_TEMPERATURE=0.0


# --- Azure OpenAI Configuration (Optional, overrides OpenAI API Key if endpoint is set) ---
# AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint_here
# AZURE_OPENAI_API_VERSION=2025-01-01-preview # For LLM
# AZURE_OPENAI_DEPLOYMENT_NAME=your_llm_deployment_name # For LLM
# AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15 # For Embeddings
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=your_embedding_deployment_name # For Embeddings
# AZURE_OPENAI_USE_MANAGED_IDENTITY=false # Set to true if using Azure Managed Identity


# --- Graphiti MCP Server Settings ---
# Optional: Group ID for namespacing graph data. If not set, a default will be used.
# GROUP_ID=my_project

# Optional: Path configuration for Docker (usually not needed if Python environment is set up correctly)
# PATH=/root/.local/bin:${PATH}

# Optional: Memory settings for Neo4j (typically used in Docker Compose, not directly by this app)
# NEO4J_server_memory_heap_initial__size=512m
# NEO4J_server_memory_heap_max__size=1G
# NEO4J_server_memory_pagecache_size=512m
